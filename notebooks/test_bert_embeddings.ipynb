{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example from TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "           output_hidden_states = True,)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_distances(texts, keyword):\n",
    "    target_word_embeddings = []\n",
    "\n",
    "    for text in texts:\n",
    "        tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "        list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "\n",
    "        # Find the position of keyword in list of tokens\n",
    "        word_index = tokenized_text.index(keyword)\n",
    "        # Get the embedding for bank\n",
    "        word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "        target_word_embeddings.append(word_embedding)\n",
    "        \n",
    "    list_of_distances = []\n",
    "    \n",
    "    for text1, embed1 in zip(texts, target_word_embeddings):\n",
    "        for text2, embed2 in zip(texts, target_word_embeddings):\n",
    "            cos_dist = 1 - cosine(embed1, embed2)\n",
    "            list_of_distances.append([text1, text2, cos_dist])\n",
    "            \n",
    "    return list_of_distances\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"bank\",\n",
    "         \"The river bank was flooded.\",\n",
    "         \"The bank vault was robust.\",\n",
    "         \"He had to bank on her for support.\",\n",
    "         \"The bank was out of money.\",\n",
    "         \"The bank teller was a man.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts2 = [\"It is a term used to describe this concept.\",\n",
    "         \"I am currently in my second term of university.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bank', 'bank', 1.0],\n",
       " ['bank', 'The river bank was flooded.', 0.33806328331314606],\n",
       " ['bank', 'The bank vault was robust.', 0.4940982832447629],\n",
       " ['bank', 'He had to bank on her for support.', 0.2561400022657283],\n",
       " ['bank', 'The bank was out of money.', 0.4699417027149666],\n",
       " ['bank', 'The bank teller was a man.', 0.4660202688464421],\n",
       " ['The river bank was flooded.', 'bank', 0.33806328331314606],\n",
       " ['The river bank was flooded.', 'The river bank was flooded.', 1.0],\n",
       " ['The river bank was flooded.',\n",
       "  'The bank vault was robust.',\n",
       "  0.5233254855624423],\n",
       " ['The river bank was flooded.',\n",
       "  'He had to bank on her for support.',\n",
       "  0.3315835872442887],\n",
       " ['The river bank was flooded.',\n",
       "  'The bank was out of money.',\n",
       "  0.5121607211837422],\n",
       " ['The river bank was flooded.',\n",
       "  'The bank teller was a man.',\n",
       "  0.5192740469056842],\n",
       " ['The bank vault was robust.', 'bank', 0.4940982832447629],\n",
       " ['The bank vault was robust.',\n",
       "  'The river bank was flooded.',\n",
       "  0.5233254855624423],\n",
       " ['The bank vault was robust.', 'The bank vault was robust.', 1.0],\n",
       " ['The bank vault was robust.',\n",
       "  'He had to bank on her for support.',\n",
       "  0.41607409928110006],\n",
       " ['The bank vault was robust.',\n",
       "  'The bank was out of money.',\n",
       "  0.7592129670024093],\n",
       " ['The bank vault was robust.',\n",
       "  'The bank teller was a man.',\n",
       "  0.8676611478954389],\n",
       " ['He had to bank on her for support.', 'bank', 0.2561400022657283],\n",
       " ['He had to bank on her for support.',\n",
       "  'The river bank was flooded.',\n",
       "  0.3315835872442887],\n",
       " ['He had to bank on her for support.',\n",
       "  'The bank vault was robust.',\n",
       "  0.41607409928110006],\n",
       " ['He had to bank on her for support.',\n",
       "  'He had to bank on her for support.',\n",
       "  1.0],\n",
       " ['He had to bank on her for support.',\n",
       "  'The bank was out of money.',\n",
       "  0.45818383355247827],\n",
       " ['He had to bank on her for support.',\n",
       "  'The bank teller was a man.',\n",
       "  0.3930241017488514],\n",
       " ['The bank was out of money.', 'bank', 0.4699417027149666],\n",
       " ['The bank was out of money.',\n",
       "  'The river bank was flooded.',\n",
       "  0.5121607211837422],\n",
       " ['The bank was out of money.',\n",
       "  'The bank vault was robust.',\n",
       "  0.7592129670024093],\n",
       " ['The bank was out of money.',\n",
       "  'He had to bank on her for support.',\n",
       "  0.45818383355247827],\n",
       " ['The bank was out of money.', 'The bank was out of money.', 1.0],\n",
       " ['The bank was out of money.',\n",
       "  'The bank teller was a man.',\n",
       "  0.7603809207327387],\n",
       " ['The bank teller was a man.', 'bank', 0.4660202688464421],\n",
       " ['The bank teller was a man.',\n",
       "  'The river bank was flooded.',\n",
       "  0.5192740469056842],\n",
       " ['The bank teller was a man.',\n",
       "  'The bank vault was robust.',\n",
       "  0.8676611478954389],\n",
       " ['The bank teller was a man.',\n",
       "  'He had to bank on her for support.',\n",
       "  0.3930241017488514],\n",
       " ['The bank teller was a man.',\n",
       "  'The bank was out of money.',\n",
       "  0.7603809207327387],\n",
       " ['The bank teller was a man.', 'The bank teller was a man.', 1.0]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding_distances(texts, 'bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
