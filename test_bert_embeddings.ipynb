{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(tokenizer, text_sentence, add_special_tokens=True):\n",
    "    text_sentence = text_sentence.replace('<mask>', tokenizer.mask_token)\n",
    "    # if <mask> is the last token, append a \".\" so that models dont predict punctuation.\n",
    "    if tokenizer.mask_token == text_sentence.split()[-1]:\n",
    "        text_sentence += ' .'\n",
    "    input_ids = torch.tensor([tokenizer.encode(text_sentence, add_special_tokens=add_special_tokens)])\n",
    "    mask_idx = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n",
    "    return input_ids, mask_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent1 = 'He went to the bank to get his water.'\n",
    "test_sent2 = 'He went to the bank to get his money.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2002, 2253, 2000, 1996, 2924, 2000, 2131, 2010, 2300, 1012,  102]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([tokenizer.encode(test_sent1, add_special_tokens=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2002, 2253, 2000, 1996, 2924, 2000, 2131, 2010, 2769, 1012,  102]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([tokenizer.encode(test_sent2, add_special_tokens=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example from TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "           output_hidden_states = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"bank\",\n",
    "         \"The river bank was flooded.\",\n",
    "         \"The bank vault was robust.\",\n",
    "         \"He had to bank on her for support.\",\n",
    "         \"The bank was out of money.\",\n",
    "         \"The bank teller was a man.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting embeddings for the target\n",
    "# word in all given contexts\n",
    "target_word_embeddings = []\n",
    "\n",
    "for text in texts:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    # Find the position 'bank' in list of tokens\n",
    "    word_index = tokenized_text.index('bank')\n",
    "    # Get the embedding for bank\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculating the distance between the\n",
    "# embeddings of 'bank' in all the\n",
    "# given contexts of the word\n",
    "\n",
    "list_of_distances = []\n",
    "for text1, embed1 in zip(texts, target_word_embeddings):\n",
    "    for text2, embed2 in zip(texts, target_word_embeddings):\n",
    "        cos_dist = 1 - cosine(embed1, embed2)\n",
    "        list_of_distances.append([text1, text2, cos_dist])\n",
    "\n",
    "distances_df = pd.DataFrame(list_of_distances, columns=['text1', 'text2', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank</td>\n",
       "      <td>bank</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bank</td>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>0.338063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bank</td>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>0.494098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank</td>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>0.256140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bank</td>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>0.469942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bank</td>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>0.466020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>bank</td>\n",
       "      <td>0.338063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>0.523325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>0.331584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>0.512161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>0.519274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>bank</td>\n",
       "      <td>0.494098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>0.523325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>0.416074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>0.759213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>0.867661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>bank</td>\n",
       "      <td>0.256140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>0.331584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>0.416074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>0.458184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>0.393024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>bank</td>\n",
       "      <td>0.469942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>0.512161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>0.759213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>0.458184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>0.760381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>bank</td>\n",
       "      <td>0.466020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>The river bank was flooded.</td>\n",
       "      <td>0.519274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>The bank vault was robust.</td>\n",
       "      <td>0.867661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>He had to bank on her for support.</td>\n",
       "      <td>0.393024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>The bank was out of money.</td>\n",
       "      <td>0.760381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>The bank teller was a man.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text1                               text2  \\\n",
       "0                                 bank                                bank   \n",
       "1                                 bank         The river bank was flooded.   \n",
       "2                                 bank          The bank vault was robust.   \n",
       "3                                 bank  He had to bank on her for support.   \n",
       "4                                 bank          The bank was out of money.   \n",
       "5                                 bank          The bank teller was a man.   \n",
       "6          The river bank was flooded.                                bank   \n",
       "7          The river bank was flooded.         The river bank was flooded.   \n",
       "8          The river bank was flooded.          The bank vault was robust.   \n",
       "9          The river bank was flooded.  He had to bank on her for support.   \n",
       "10         The river bank was flooded.          The bank was out of money.   \n",
       "11         The river bank was flooded.          The bank teller was a man.   \n",
       "12          The bank vault was robust.                                bank   \n",
       "13          The bank vault was robust.         The river bank was flooded.   \n",
       "14          The bank vault was robust.          The bank vault was robust.   \n",
       "15          The bank vault was robust.  He had to bank on her for support.   \n",
       "16          The bank vault was robust.          The bank was out of money.   \n",
       "17          The bank vault was robust.          The bank teller was a man.   \n",
       "18  He had to bank on her for support.                                bank   \n",
       "19  He had to bank on her for support.         The river bank was flooded.   \n",
       "20  He had to bank on her for support.          The bank vault was robust.   \n",
       "21  He had to bank on her for support.  He had to bank on her for support.   \n",
       "22  He had to bank on her for support.          The bank was out of money.   \n",
       "23  He had to bank on her for support.          The bank teller was a man.   \n",
       "24          The bank was out of money.                                bank   \n",
       "25          The bank was out of money.         The river bank was flooded.   \n",
       "26          The bank was out of money.          The bank vault was robust.   \n",
       "27          The bank was out of money.  He had to bank on her for support.   \n",
       "28          The bank was out of money.          The bank was out of money.   \n",
       "29          The bank was out of money.          The bank teller was a man.   \n",
       "30          The bank teller was a man.                                bank   \n",
       "31          The bank teller was a man.         The river bank was flooded.   \n",
       "32          The bank teller was a man.          The bank vault was robust.   \n",
       "33          The bank teller was a man.  He had to bank on her for support.   \n",
       "34          The bank teller was a man.          The bank was out of money.   \n",
       "35          The bank teller was a man.          The bank teller was a man.   \n",
       "\n",
       "    distance  \n",
       "0   1.000000  \n",
       "1   0.338063  \n",
       "2   0.494098  \n",
       "3   0.256140  \n",
       "4   0.469942  \n",
       "5   0.466020  \n",
       "6   0.338063  \n",
       "7   1.000000  \n",
       "8   0.523325  \n",
       "9   0.331584  \n",
       "10  0.512161  \n",
       "11  0.519274  \n",
       "12  0.494098  \n",
       "13  0.523325  \n",
       "14  1.000000  \n",
       "15  0.416074  \n",
       "16  0.759213  \n",
       "17  0.867661  \n",
       "18  0.256140  \n",
       "19  0.331584  \n",
       "20  0.416074  \n",
       "21  1.000000  \n",
       "22  0.458184  \n",
       "23  0.393024  \n",
       "24  0.469942  \n",
       "25  0.512161  \n",
       "26  0.759213  \n",
       "27  0.458184  \n",
       "28  1.000000  \n",
       "29  0.760381  \n",
       "30  0.466020  \n",
       "31  0.519274  \n",
       "32  0.867661  \n",
       "33  0.393024  \n",
       "34  0.760381  \n",
       "35  1.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
